> 原书15, 16章暂且跳过.

# 所有资源

![](assert/Pasted%20image%2020220811140522.png)
# `Pod`生命周期

* 应用必须预料到会被杀死或者重新调度 :: 在 `k8s` 之外运行的应用很少会被从一台机器迁移到另外一台. 当一个操作者迁移应用的时候, 他们可以重新配置应用并且手动检查应用是否正常运行. 然后在 `k8s` 中, 应用会更加频繁地进行自动迁移而无须人工介入. 也就是说没有人会再对应用进行配置并且确保它们在迁移之后能够正常运行.
* 预料到写入磁盘的数据会丢失 :: 在重新调度的时候数据丢失是一定的, 即使在没有调度的情况下, 写入磁盘的文件也会丢失, 比如容器崩溃或者被杀死, 这时候 `pod` 是一样的, 但容器已经是新的了.
* 使用存储卷来跨容器持久化数据.

有时候使用存储卷来存储数据是个好办法. 不过如果由于数据损坏导致新创建的进程再次崩溃, 这会导致一个持续性的循环崩溃. 如果不适用存储卷的话, 新的容器会从零开始启动, 并且很可能不会崩溃. 所以这是把双刃剑需要考虑是否真的需要.

# 重新调度死亡或者部分死亡的 `pod`

如果一个 `pod` 的容器一直处于崩溃状态, `kubelet` 将会一直不停地重启它们. 每次重启的时间间隔将会以指数级增加, 直到达到5分钟. 在5分钟的时间间隔中,  `pod` 基本上是死亡了, 因为它们的容器进程没有运行. 然而即使完全死亡并且毫无用处, 但它们不会被自动移除或重新调度.
![](assert/Pasted%20image%2020220811150344.png)

由于 `pod` 是运行在容器中的, 因此一个节点无法调度的话其它节点大概率也可能无法调度, 所以不会去调度死亡的 `pod`. 在某种程度上, 可以理解 `k8s` 这么做.

容器将会每五分钟重启一次, 在这个过程中 `k8s` 期望底层崩溃的原因会被解决. 所有的节点理论上都是在容器内部有着相同的崩溃原因. 虽然并不总是如此, 但是大多数情况下是这样的.

# 以固定顺序启动 `pod`

可以通过在 `pod` 中包含叫做 `init` 的容器来实现. 一个 `pod` 可以拥有任意数量的 `init` 容器. `init` 容器是按顺序执行的, 并且仅当最后一个执行完毕才会去启动主容器. 换句话说, `init` 容器也可以用来延迟 `pod` 的主容器的启动.

![](assert/Pasted%20image%2020220811150920.png)

应用需要能够应对它所依赖的服务没有准备好的情况. 另外也不要忘了 `Readiness` 探针. 如果一个应用在其中一个依赖缺失的情况下无法工作, 那么它需要通过它的 `Readiness` 探针来通知这个情况.

# 生命周期钩子

* postStart
* preStop

![](assert/Pasted%20image%2020220811153101.png)

钩子和主进程并行执行的, 它并不是等到主进程完全启动后才执行. 即使钩子是异步的, 但也通过两种方式影响容器. 在钩子执行完毕之前, 容器会一直停留在 `waiting` 状态. 如果钩子运行失败或者返回了非零的状态码, 主容器会被杀死.

如果钩子程序启动的进程将日志输出到标准输出终端, 那么就无法被看到. 这样会导致调试生命周期钩子程序很痛苦. 如果钩子程序失败了仅仅会在 `pod` 的事件中看到一个 `FailedPostStartHook` 的警告信息.

基于命令的启动, 钩子输出到标准输出和错误输出的内容在任何地方不会被记录, 因此如果想要查看的话可以通过存到一个文件中然后通过命令 `kubectl exec my-pod -- cat logfile.txt`. 或者挂载一个 `emptyDir` 卷让钩子程序向卷中写入内容.

停止前钩子会在容器终止之前执行, 并且仅在执行完钩子程序后才会向容器进程发送 `SIGTERM` 信号(如果没有优雅地终止运行, 则会被直接杀死).

可以利用停止前钩子来让容器以优雅的方式关闭. 这些钩子也可以在容器终止之前执行任意的操作. 并且不需要再应用内部去实现.

![](assert/Pasted%20image%2020220811153839.png)

和启动后钩子不同的是, 不管钩子执行成功与否都会被终止. 如果执行失败了会在 `pod` 实践中看到一个告警, 但是因为 `pod` 不久就会被删除了, 或许都看不到停止前钩子执行失败.

**在应用没有收到 `SIGTERM`信号时使用停止前钩子**

很多开发者在定义停止前钩子会只向应用发送 `SIGTERM` 信号. 这样做是因为他们没有看到他们的应用接收到 `kubelet` 发送的 `SIGTERM` 信号. 应用没有接收到信号的原因并不是 `k8s` 没有发送信号, 而是在容器内部信号没有被传递给应用的进程. 比如容器镜像配置是通过执行一个 `shell` 进程, 然后在 `shell` 进程内部执行应用进程, 那么这个信号就会被 `shell` 进程吞没导致子进程没收到.

在这种情况下合理的做法应该是让 `shell` 传递信号给应用程序, 而不是添加停止前钩子.

使用 `ENTRYPOINT /binary` 会先运行一个 `shell` 作为主进程, 然后 `binary` 作为子进程运行.
而 `ENTRYPOINT ["/binary"]` 则会直接以主进程执行.

> 需要注意的是, 生命周期钩子是针对容器而不是 `pod`. 在 `pod` 的生命周期中可能会多次执行容器的生命周期钩子.


# 了解 `pod` 的关闭

`pod` 关闭从 `API`服务器接收到 `HTTP DELETE` 请求后开始. 先会给 `pod` 设置一个 `deletionTimestamp`, 当 `kubelet` 意识到需要终止的时候, 先开始终止 `pod` 中的每个容器. `kubelet` 会给每个容器一定的时间来优雅停止. 这个时间叫做终止宽限期(Termination GracePeriod), 每个 `pod` 可以单独配置. 在终止进程开始后, 计时器就开始计时执行以下事件:

1. 执行停止前钩子
2. 向主进程发送 `SIGTERM` 信号
3. 等待容器优雅关闭或者等待终止宽限期超时
4. 使用 `SIGKILL` 强制终止

终止宽限期通过 `spec.terminationGracePeriodPeriods` 字段设置, 默认为30. 或者命令行覆盖:

```bash
kubectl delete po xxx --grace-period=5
```

**在应用中合理处理容器关闭操作**

当无法保证关闭流程能够在进程被杀死前执行完毕的时候, 可以考虑在停止前钩子中创建一个 `Job` 去执行关闭流程, 比如数据迁移之类的操作.

然而也可能在没有创建成功 `Job` 的时候就出现了故障. 合理的解决方案是用一个专门的持续运行中的 `pod` 来持续检查是否存在孤立的数据. 当发现孤立的数据时就可以把它们迁移到扔存活的 `pod`. 当然也可以使用 `CronJob` 来周期检查.

使用专门的 `pod` 迁移数据:

![](assert/Pasted%20image%2020220811161226.png)

# 确保来自客户端的请求都妥善处理

## 在 `pod` 启动时避免客户端连接断开

在 `pod` 上添加就绪探针, 否则会总是准备好的, 这样可能会使得所有客户端接收到连接被拒绝之类的信息.

## 在 `pod` 关闭时避免客户端连接断开

在删除 `pod` 的时候, `API` 服务器会同时通知删除事件到观察者, 其中两个就是 `kubelet` 和 `endpoint controller`. 

![](assert/Pasted%20image%2020220811164431.png)

然而在另一边, 每个 `kube-proxy` 服务都会在自己的节点上更新 `iptables` 规则, 这两串事件时同时发生的. 最有可能的是 `iptables` 的时间稍长一些, 因为这些事件到达 `endpoint controller` 后, `endpoint controller` 向 `API` 服务器发送新的请求, 然后 `API` 服务器发送事件到 `kube-proxy`. 一个很大的可能性是 `SIGTERM` 信号会在 `iptables` 规则更新到节点之前发送出去.

可能的结果是, 在发送终止信号到 `pod` 之后, `pod` 仍然可能接收客户端请求, 这就导致客户端会收到连接被拒绝之类的错误.

![](assert/Pasted%20image%2020220811164840.png)

### 解决方法

可以做的唯一的合理的事情就是等待足够长的时间让所有的 `kube-proxy` 可以完成工作. 通常情况下可能需要几秒, 但不能保证每次都足够. 然而增加更长的延迟也会使得用户体验收到影响, 并且太长的时间会导致 `pod` 被删除很长一段时间后还显示在列表里.

* 等待几秒钟, 然后停止接收新的连接
* 关闭所有没有请求过来的长连接
* 等待所有的请求都完成
* 完全关闭应用

![](assert/Pasted%20image%2020220811165219.png)

这个过程不像进程接收到终止信号立即退出那么简单. 是否值得需要考虑. 不过至少可以添加一个停止前钩子来等待几秒钟再退出.

# 构建可管理的容器镜像

在实践中, 如果构建最小化容器的话, 会比较难以调试, 例如没有 `ping`, `dig`, `curl` 之类的工具. 一般会让容器至少再包含这些工具的最小集合.

合理的给镜像打标签, 否则使用 `latest` 的话可能在同一个 `deployment` 中会运行不同版本的 `pod` 副本.

## 给进程终止提供更多的信息

进程需要写入终止信息的文件默认路径是 `/dev/termination-log`, 可以修改.

![](assert/Pasted%20image%2020220811165852.png)

![](assert/Pasted%20image%2020220811165902.png)

也可以通过将 `terminationMessagePolicy` 设为 `FallbackToLogsOnError`, 在这种情况下, 容器最后几行的日志会被当作终止信息(当然也是仅当容器没有成功终止的情况下).


# 处理应用日志

```bash
# stdout
kubectl logs xxx
kubectl logs --previous
kubectl exec <pod> -- cat <logfile>
kubectl cp pod:/var/log/foo.log foo.log
```

也可以使用集中式日志记录, 除了 `ElasticSearch`, `Logstash`, `Kibana` 组成的 `ELK`, 还有 `ELF` (`FluentD`) 技术栈. 通过使用 `DaemonSet` 部署 `FluentD` 代理, 从容器中搜集日志, 然后打上和 `pod` 相关的信息, 最后发送给 `ElasticSearch`, 之后通过 `Kibana` 查看与分析.

# 工具

使用 `Ksonnet` 编写清单文件